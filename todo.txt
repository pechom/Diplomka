na selekciu a klasifikaciu pouzijem len SVC (L1), XGBOOST a LGBM
vyber len 50 a 100 atributov
Krosvalidaciu pouzijem na vysledky - presnost pred a po selekcii (a pripadny hyperparameter tuning) lebo je robustna. Po selekcii pouzijem cely dataset na trenovanie (s rovnakymi parametrami) a potom z natrenovaneho modelu urobim predikciu.

netreba pre V2 - pred cistenim datasetu zmenit v novych reportoch AV text vysledkov skenov na "detected: True/False" - aspon na vybranych AV. Potrebujem to pre cistenie datasetu aj labeling

netreba pre V2 - ziskat metadata (exiftool) pre nove vzorky a dopisat ich do reportov v rovnakej strukture ako je v starych

done - v labeling ulozit premenu tried na ich cisla (zoznam), pridat metodu na labeling vzoriek na predikciu konsenzom podla zoznamu (vyhodim vzorky ktore maju triedu mimo zoznamu aj ked dosiahli konsenzus, triedam dam rovnake cisla ako v zozname)
        Clustering je nemozny (mam vzdialenosti, nie body. Reclustering moze zmenit stare triedy)
    
done - v extrakcii pridat nazvy atributov v hlavickach, pridat ich aj do selekcie - poriesit delimetre v nazvoch

done - Po selekcii urobit na nestandardizovanych selektovanych datach novu standardizaciu (pri standardizovanych musim ulozit aj nestandardizovane atributy) a jej scaler ulozit a pouzit pri predikcii. Pouzit ho aj pri vysledkoch klasifikacie
        po selekcii (namiesto pôvodnych vysledkov) - metoda check_selections. Pre kazdu selekciu vznikne novy scaler.
        
done - v klasifikacii pridat predikciu a perzistenciu naucenych klasifikatorov. Ukladat vysledky - predikovane triedy (z nich sa urobi heat map).

done - v extrakcii pridat metody (alebo rozsirit stare) na extrakciu len selektovanych atributov pre predikovane vzorky podla ulozenej hlavicky (pre kazdu hlavicku osobitne) - pozor na skupiny atributov podla predpony. 
        Tato extrakcia bude uz len podla novych reportov. Pre kazdu hlavicku zavolam aj metody z preprocessing kde original file bude nazov hlavicky - podla neho urcim scaler na pouzitie
        Atributy budu zo zoznamu (hlavicka selekcie pre rôzne selekcie) a podla nich sa vytvori matica datasetu na predikciu.
        Pre kazdu hlavicku pouzijem aj preprocessing (so saved_standardize) aby som vytvoril subor s jej nazvom a pouzil jej scaler.
        Pri volani preprocessing musim zmenit original file na meno hlavicky - rovnake meno ma scaler (v scalers_path).
        Po skonceni preprocessingov ulozit original subory do selected_dir a standardizovane do standard_selected_dir
        Do vsetkych metod pridat este osetrenie stavu, ked clear_prefix_from_header vrati prazdnu hlavicku - ziaden atribut skupiny nebol selektovany. V tom pripade vratit z metody hned prazdnu hlavicku a nezapisovat nic do csv.
        Osetrit prazdny vysledok zo selekcie aj v povodnych metodach - ak je prazdna hlavicka, dalej v nej nepokracovat
        
done - v results urobit heat map a accuracy pre predikcie (cez predikovane vysledky a realne labels, mena tried budu z class_number. Triedy su v confusion matrix ciselne zoradene)

done - v results upravit metody tak, aby spracovali nove hlavicky

done - v results pocitaj aj pocet atributov pre predikovane vysledky ktore maju 0 varianciu aby som vedel kolko zo selektovanych atributov bolo aj pouzitelnych

! in progress - testovanie

low priority - automatizovat tvorbu grafu pre vysledky. Pridat graf aj pre predikcie
